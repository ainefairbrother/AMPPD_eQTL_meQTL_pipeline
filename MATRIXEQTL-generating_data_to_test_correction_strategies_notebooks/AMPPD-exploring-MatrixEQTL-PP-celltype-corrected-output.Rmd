---
title: "Exploring `MatrixEQTL` output"
author: "Aine Fairbrother-Browne"
date: "11/21"
output: 
  html_document:
    theme: paper
    highlight: kate
    df_print: paged
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: false  
    fig_width: 20
    fig_height: 15
    fig_caption: true
---

**Aim**: To explore and QC AMP-PD `MatrixEQTL` output. In this instance, the input was PPMI data, with cell type proportions added to the covariate files. 

# Setup  

```{r setup, include=FALSE}

# import libs
library(tidyverse)
library(qqman)
library(devtools)
library(Biobase)
library(MatrixEQTL)
library(broom)
library(lemon)
library(qs)
library(ggrepel)
library(fst)
library(patchwork)
library(data.table)
library(BSgenome)
library(parallel)
# library for HTTP requests
library(httr)
library(genio) 

# notebook settings 
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/home/abrowne/projects/amppd_analysis/")

```

# Wrangle individual pheno files  

* The `read.matrixeqtl.pheno.output.wrangle.write()` function reads in the `MatrixEQTL` output and wrangles it to prepare for downstream analyses  
+ Annotate data with information from filename: cohort, diagnosis, phenotype, model  
+ Annotate data with rsIDs  
+ Calculate the standard error of the estimate:
+ The SE of the estimate is needed to run meta-analyses downstream  
+ Matrix eQTL currently reports estimates of the effect size (slope coefficient) and the corresponding t-statistics, but does not report the     standard errors for the effect size. By definition a t-statistic is equal to the effect size estimate divided by its standard error. Thus, the     standard deviation of the estimate can be easily calculated as the ration of the effect size estimates and their t-statistics.  
+ `me$all$eqtls$beta_se = me$all$eqtls$beta / me$all$eqtls$statistic`   

```{r include=FALSE, eval=FALSE}

## convert_rs_to_loc.R setup ## 

# # load Regina's function from the coloc package - https://github.com/RHReynolds/colochelpR/blob/master/R/convert_rs_to_loc.R
# source("/home/rreynolds/packages/colochelpR/R/convert_rs_to_loc.R")
#
# # df dataframe. Dataframe containing SNPs as genomic locations. Must
# # contain 2 columns labelled \code{CHR} and \code{BP}, with chromosome and
# # base pair positions, respectively. If the dataframe contains additional
# # columns included these will be preserved.
# # dbSNP BS genome reference snps (choose appropriate dbSNP build
# # dependent on genome build).
#
# # What SNPlocs data packages are already installed:
# BSgenome::installed.SNPs()
# 
# # What SNPlocs data packages are available:
# BSgenome::available.SNPs()
# 
# # extend install/DL time to allow DL of SNPlocs.Hsapiens.dbSNP151.GRCh38
# options(timeout=1000)
# 
# # select the latest dbSNP, SNPlocs.Hsapiens.dbSNP151.GRCh38, and install
# BiocManager::install("SNPlocs.Hsapiens.dbSNP151.GRCh38")
# 
# # # assign dbSNP obj to variable
# library(SNPlocs.Hsapiens.dbSNP151.GRCh38)
# dbSNP = SNPlocs.Hsapiens.dbSNP151.GRCh38

```

```{r eval=FALSE}

read.matrixeqtl.pheno.output.wrangle.write = function(path, pattern){
  
  setwd(path)
  
  # get all the files to wrangle
  file.list = list.files(path=path, pattern=pattern, full.names=F)
  
  # define function to apply to each matrixeqtl output file in file.list
  wrangle.write.file=function(X){
    
    # for stop-start running - don't generate file if it already exists
    #if(file.exists(gsub("MatrixEQTL", "wrangled", X))==FALSE){
    
    # extract relevant info from file name
    extracted.groups = stringi::stri_match_all(X, regex="^([A-Z]{2})_([A-Za-z]+)_pheno=(.+)_maf=(.+)_phenotype=([A-Za-z]+)_model=([A-Za-z]+)_MatrixEQTL.csv")[[1]]
    
    # read in and wrangle - add file name info as columns 
    vroom::vroom(file=X, delim = "\t", escape_double = FALSE, trim_ws = TRUE) %>% 
      dplyr::mutate(
        beta=as.numeric(beta),
        `t-stat`=as.numeric(`t-stat`),
        `p-value`=as.numeric(`p-value`),
        `FDR`=as.numeric(`FDR`),
        cohort=rep(extracted.groups[,2], nrow(.)),
        diagnosis=extracted.groups[,3],
        phenotype=extracted.groups[,4],
        nuc.snp.maf.filter=extracted.groups[,5],
        phenotype.category=extracted.groups[,6],
        matrixeqtl.model.run=extracted.groups[,7]) %>% 
      
      # do some additional tidying of cols
      tidyr::separate(col=SNP, into=c("chr", "start"), sep="-") %>% 
      dplyr::select(-gene) %>% 
      dplyr::mutate(chr.pos = paste0(chr, ":", start)) %>% 
      dplyr::relocate(chr.pos, chr, start, phenotype) %>% 
      dplyr::rename(snp.chr.pos=chr.pos, snp.chr=chr, snp.start=start) %>% 
      dplyr::rename(p.value = `p-value`, t.stat = `t-stat`) %>%  
      
      #   # # Assign rsid: prep data for convert_loc_to_rs.R
      #   # pos.to.snp = d %>% 
      #   #   dplyr::select(snp.chr, snp.start) %>% 
      #   #   dplyr::rename(CHR=snp.chr, BP=snp.start) %>% 
      #   #   # implement Regina's function from the coloc package - https://github.com/RHReynolds/colochelpR/blob/master/R/convert_rs_to_loc.R
      #   #   convert_loc_to_rs(df=., dbSNP = dbSNP) %>% 
      #   #   # rename to make cols compatible with matrixeqtl.out.df
      #   #   dplyr::rename(snp.chr=CHR, snp.start=BP) 
      #   
      #   # Assign rsid: re-join the original table to pos.to.snp - this is the table where pos are mapped to rsid 
    dplyr::mutate(snp.chr=gsub("chr", "", snp.chr)) %>% 
      dplyr::mutate(snp.start=as.numeric(snp.start)) %>% 
      # # dplyr::left_join(x=., 
      # #                  y=pos.to.snp %>% 
      # #                    tibble::tibble() %>% 
      # #                    dplyr::mutate(snp.chr=as.character(snp.chr)) %>% 
      # #                    dplyr::mutate(snp.start=as.numeric(snp.start)), 
      # #                  by=c("snp.chr", "snp.start")) %>% 
      # # dplyr::distinct() %>% 
      
      dplyr::arrange(p.value) %>% 
      
      # calculate the standard error of the beta - useful for downstream meta-analyses
      dplyr::mutate(beta_se = beta/t.stat) %>% 
      
      # write out
      vroom::vroom_write(x=., file=gsub("MatrixEQTL", "wrangled", X), delim=",")
  }
  
  parallel::mclapply(file.list, wrangle.write.file, mc.cores=4)
}

```

* Implement `read.matrixeqtl.pheno.output.wrangle.write`  

```{r message=FALSE, warning=FALSE, eval=FALSE}

read.matrixeqtl.pheno.output.wrangle.write(path="/home/abrowne/projects/amppd_analysis/data/MatrixEQTL_output/celltype_PP_samples_filtered/", pattern="MatrixEQTL.csv")

```

# Plot `MatrixEQTL` results    

## Generate Manhattan plots for all cohorts, diagnoses, models and phenotypes  

* Code for the `plot.manhattan()` function adapted from: https://www.r-graph-gallery.com/101_Manhattan_plot.html  
* Red line indicates genome-wide significance at P=5e-8  

```{r eval=FALSE}

plot.manhattan = function(which.dir="/home/abrowne/projects/amppd_analysis/data/MatrixEQTL_output/celltype_PP_samples_filtered/", which.cohort, which.diagnosis, which.model, which.phenotype, which.phenocat, print.or.save){
  
  f=paste0(which.dir,which.cohort,"_",which.diagnosis,"_pheno=",which.phenotype,"_maf=0.05_phenotype=",which.phenocat,"_model=",which.model,"_wrangled.csv")
  
  if(file.exists(f)==FALSE){
    print(paste("file", f, "does not exist"))}
  else if(file.exists(f)==TRUE){
    
    # filter the dataset for the input args
    gwasResults = readr::read_csv(f) %>% 
      # replace X and Y chr labels with numbers
      dplyr::mutate(snp.chr = replace(snp.chr, snp.chr == "X", 23)) %>% 
      dplyr::mutate(snp.chr = replace(snp.chr, snp.chr == "Y", 24)) %>% 
      dplyr::mutate(snp.chr=as.numeric(snp.chr)) %>% 
      
      # rename for compatibility 
      dplyr::rename(
        # SNP=SNP,
        CHR=snp.chr,
        BP=snp.start,
        P=p.value # change to p.value for raw or FDR for corrected
      ) 
    
    if(dim(gwasResults)[1]!=0){
      
      don = gwasResults %>% 
        
        # Compute chromosome size
        dplyr::group_by(CHR) %>% 
        dplyr::summarise(chr_len=max(BP)) %>% 
        dplyr::mutate(chr_len=as.numeric(chr_len)) %>% 
        
        # Calculate cumulative position of each chromosome
        dplyr::mutate(tot=cumsum(chr_len)-chr_len) %>%
        dplyr::select(-chr_len) %>%
        
        # Add this info to the initial dataset
        dplyr::left_join(gwasResults, ., by=c("CHR"="CHR")) %>%
        
        # Add a cumulative position of each SNP
        tidyr::drop_na(CHR) %>% 
        tidyr::drop_na(BP) %>% 
        dplyr::arrange(CHR, BP) %>% 
        dplyr::mutate( BPcum=BP+tot) %>% 
        
        # Add highlight and annotation information
        #mutate( is_highlight=ifelse(SNP %in% snpsOfInterest, "yes", "no")) %>%
        mutate(is_annotate=ifelse(P<5e-8, "yes", "no")) 
      
      axisdf = don %>% 
        dplyr::group_by(CHR) %>% 
        dplyr::summarize(center=( max(BPcum) + min(BPcum) ) / 2 )
      
      plot = ggplot(don, aes(x=BPcum, y=-log10(P))) +
        
        # Show all points
        geom_point(aes(color=as.factor(CHR)), alpha=0.75, size=0.8) +
        scale_color_manual(values = rep(c("grey", "black"), 22)) +
        
        # custom X axis:
        scale_x_continuous(label = axisdf$CHR, breaks= axisdf$center) +
        scale_y_continuous(limits = c(0, 15), expand = c(0, 0)) +     # remove space between plot area and x axis
        
        # custom theme:
        theme_bw() +
        theme( 
          legend.position="none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()
        ) + 
        geom_hline(yintercept = -log10(5e-8), colour="red", alpha=0.5)  + 
        xlab("Genomic position") +
        
        # custom theme:
        theme_bw(base_size = 8) +
        theme( 
          legend.position="none",
          panel.border = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()
        ) +
        ggtitle(paste(which.cohort, which.diagnosis, which.phenotype, which.model))
      
      # Add highlighted points
      #geom_point(data=subset(don, is_highlight=="yes"), color="orange", size=2) +
      
      # Add label using ggrepel to avoid overlapping
      #ggrepel::geom_label_repel(data=subset(don, is_annotate=="yes"), aes(label=SNP), size=2)
      
      if(print.or.save=="print"){return(plot)}
      if(print.or.save=="save"){
        
        savePlot <- function(the.plot, out.name) {
          png(paste(out.name), width = 5, height = 3, units="in", res=200)
          print(the.plot)
          dev.off()
        }
        
        savePlot(the.plot=plot, out.name=paste0(which.dir, "manhattan_plots/",which.cohort,"_",which.diagnosis,"_",which.phenotype,"_",which.model,"_manhattan_pvalue.png"))
      }
    }
  }
}

```

* Implement `plot.manhattan()`  

```{r message=FALSE, warning=FALSE, eval=FALSE}

for(cohort in c("PP")){ 
  
  for(diag in c("Case", "Control")){
    
    for(pheno in c("ENSG00000198888", "ENSG00000198763", "ENSG00000198840",
                   "ENSG00000212907", "ENSG00000198886", "ENSG00000198786", 
                   "ENSG00000198695","ENSG00000198712", "ENSG00000198938", 
                   "ENSG00000228253", "ENSG00000198727", "ENSG00000198804", 
                   "ENSG00000198899", "ENSG00000211459","ENSG00000210082")){
      plot.manhattan(
        which.cohort=cohort, 
        which.diagnosis=diag, 
        which.model="LINEAR", 
        which.phenotype=pheno,
        which.phenocat="expression",
        print.or.save="save")
    }}}

for(cohort in c("PP")){ 
  
  for(diag in c("Case", "Control")){
    
    for(pheno in c("3238_full", "4271_full", "4392_full", "5520_full", 
                   "5647_full", "5721_full", "5818_full", "5883_full", 
                   "7526_full", "8303_full", "9999_full", "10413_full", 
                   "12146_full", "12274_full", "14734_full", "15896_full", 
                   "15948_full", "2617_full", "13710_full")){
      plot.manhattan(
        which.cohort=cohort, 
        which.diagnosis=diag,  
        which.model="LINEAR", 
        which.phenotype=pheno,
        which.phenocat="methylation",
        print.or.save="save")
    }}}

for(cohort in c("PP")){ 
  for(pheno in c("ENSG00000198888", "ENSG00000198763", "ENSG00000198840",
                 "ENSG00000212907", "ENSG00000198886", "ENSG00000198786", 
                 "ENSG00000198695","ENSG00000198712", "ENSG00000198938", 
                 "ENSG00000228253", "ENSG00000198727", "ENSG00000198804", 
                 "ENSG00000198899", "ENSG00000211459","ENSG00000210082")){
    plot.manhattan(
      which.cohort=cohort, 
      which.diagnosis="cohort", 
      which.model="LINEARCROSS", 
      which.phenotype=pheno,
      which.phenocat="expression",
      print.or.save="save")
  }}

for(cohort in c("PP")){ 
  for(pheno in c("3238_full", "4271_full", "4392_full", "5520_full", 
                 "5647_full", "5721_full", "5818_full", "5883_full", 
                 "7526_full", "8303_full", "9999_full", "10413_full", 
                 "12146_full", "12274_full", "14734_full", "15896_full", 
                 "15948_full", "2617_full", "13710_full")){
    plot.manhattan(
      which.cohort=cohort, 
      which.diagnosis="cohort", 
      which.model="LINEARCROSS", 
      which.phenotype=pheno,
      which.phenocat="methylation",
      print.or.save="save")
  }}

```

# Annotate with rsIDs  

## Define helper functions  

```{r}

parallel.helper = function(fn, path, pattern, cores.to.use=3){
  
  # Run a function, fn, across files matching pattern, pattern, in directory, path. 
  # This will produce whatever files fn is designed to output
  file.list = list.files(path=path, pattern=pattern, full.names=T)
  parallel::mclapply(file.list, fn, mc.cores=cores.to.use)
  
}

lapply.helper = function(fn, path, pattern){
  
  # Run a function, fn, across files matching pattern, pattern, in directory, path. 
  # This will produce whatever files fn is designed to output
  file.list = list.files(path=path, pattern=pattern, full.names=T)
  lapply(X=file.list, FUN=fn)
  
}

loop.helper = function(fn, path, pattern){
  
  file.list = list.files(path=path, pattern=pattern, full.names=T)
  for(i in 1:length(file.list)){
    fn(file.list[i])
  }
}

```

## Import dbSNP  

```{r, eval=FALSE}

# Assign rsid: import Regina's convert_rs_to_loc.R function
source("/home/rreynolds/packages/colochelpR/R/convert_rs_to_loc.R")
# Assign rsid: assign dbSNP obj to variable - prerequisite for convert_rs_to_loc.R 
library(SNPlocs.Hsapiens.dbSNP151.GRCh38)
dbSNP = SNPlocs.Hsapiens.dbSNP151.GRCh38

```

## Map rsIDs  

```{r message=FALSE, warning=FALSE, eval=FALSE}

annotate.wrangled.pheno.file.rsid.overwrite = function(file.path){
  
  d = vroom::vroom(file.path) %>% 
    tidyr::extract(col=snp.chr.pos, into="snp.chr", regex="chr(.+):", remove=FALSE)
  
  # if the df is not empty, continue with wrangling
  if(dim(d)[1]!=0){
    # if the file already has the col, don't add 
    if( !("SNP" %in% colnames(d)) ){
      
      d %>%
        dplyr::select(snp.chr, snp.start) %>%
        dplyr::rename(CHR=snp.chr, BP=snp.start) %>%
        # implement Regina's function from the coloc package - https://github.com/RHReynolds/colochelpR/blob/master/R/convert_rs_to_loc.R
        convert_loc_to_rs(df=., dbSNP = dbSNP) %>%
        # rename to make cols compatible with d
        dplyr::rename(snp.chr=CHR, snp.start=BP) %>%
        tibble::tibble() %>%
        dplyr::mutate(snp.chr=as.character(snp.chr)) %>%
        dplyr::mutate(snp.start=as.numeric(snp.start)) %>% 
        dplyr::left_join(x=d, y=., by=c("snp.chr", "snp.start")) %>%
        dplyr::distinct() %>% 
        vroom::vroom_write(x=., file=file.path)
      
      print(paste("DONE", file.path))
    }
  }
}

```

```{r message=FALSE, warning=FALSE, eval=FALSE}

file.list = list.files(path="/home/abrowne/projects/amppd_analysis/data/MatrixEQTL_output/celltype_PP_samples_filtered/", pattern="wrangled.csv", full.names=T)
for(i in 1:length(file.list)){
  print(file.list[i])
  annotate.wrangled.pheno.file.rsid.overwrite(file.path=file.list[i])
}

```

# Calculate peak SNP in megabase block  

* I can do this using hierarchical clustering  
* The function `assign.mb.block.to.group()` applies the hierarchical clustering algorithm group-wise  
* The function `apply.assign.mb.fn.to.file.and.write.out()` groups a dataframe and applies `assign.mb.block.to.group()`  
* Cohort-diagnosis-phenotype-model grouped files individually passed to `assign.mb.block.to.group()`, where they are grouped by chr, meaning that megabase blocks are then assigned chr-wise  

```{r message=FALSE, warning=FALSE, eval=FALSE}

assign.mb.block.to.group = function(group){
  
  # group= d %>% 
  #   slice_head(n=100)
  
  # This function assigns, to a group of a df, block IDs, mb.block.id, to a cluster of row values
  # Rows are clustered based on the SNP position
  # Then the tree is cut to get positions that are within a series of megabase blocks
  # Positions in these blocks are given the same mb.block.id
  # It then determines the peak (min. p.value) SNP in the block 
  # The output is a modified group in tibble format 
  
  block.size=1000000
  
  # get distance tree by calculating the complete distance between positions
  tree = hclust(dist(group$snp.start), method = "complete")
  
  ##### test tier to check that the blocks (max-min) span 1mb  ##### 
  # split into 1MB clusters
  blocks = split(group$snp.start, cutree(tree, h = block.size)) %>%
    `names<-`(paste0("block",names(.)))
  
  # check that the block range is less than 1mb - for each block
  error.count=0
  for(i in 1:length(blocks)){
    le.1mb = ((blocks[[i]] %>% max()) - (blocks[[i]] %>% min()) < block.size)
    if(le.1mb==FALSE){error.count=error.count+1}
  }
  if(error.count != 0){print(error.count)}
  
  #######################################################
  
  # split distance tree into 1MB clusters 
  return(
    split(group$snp.start, cutree(tree, h=block.size)) %>% 
      # name the clusters
      `names<-`(paste0("block",names(.))) %>% 
      # make list of 1MB blocks into df 
      stack() %>% 
      dplyr::rename(snp.start=values, mb.block.id=ind) %>% 
      # join to original df group
      dplyr::left_join(x=group, y=., by="snp.start")
  )
}

```

```{r message=FALSE, warning=FALSE, eval=FALSE}

apply.assign.mb.fn.to.file.and.write.out = function(file.path){
  
  # This function takes in a file, and applies to it the assign.mb.block.to.group function which outputs a modified group
  # It does this using group_modify, which applies a function that outputs a modified group to all groups in a df
  # It then does some cleaning 
  # Then writes out the output, overwriting the input file 
  
  print(file.path)
  
  d = vroom::vroom(file.path) %>% 
    tidyr::extract(col=snp.chr.pos, into="snp.chr", regex="chr(.+):", remove=FALSE)
  
  # if the df is not empty, continue with wrangling
  if(dim(d)[1]!=0){
    
    # if the mb.block.id.chr is not present, continue with wrangling
    if( !("mb.block.id" %in% colnames(d)) ){
      d %>% 
        dplyr::group_by(snp.chr, .drop=FALSE) %>%
        dplyr::group_modify(~assign.mb.block.to.group(.x)) %>% 
        dplyr::mutate(chr.mb.block.id=paste0(snp.chr,".",mb.block.id)) %>% 
        # group by snp.chr and mb.block.id in order to get 'peak snp' in MB block - aka SNP with lowest p.value
        dplyr::group_by(chr.mb.block.id, .drop=FALSE) %>%
        dplyr::mutate(min.pval.in.mb.block=min(p.value)) %>%
        dplyr::ungroup() %>% 
        # dplyr::arrange(.by_group = TRUE) %>%
        vroom::vroom_write(x=., file=file.path)
    }
  }
}

```

```{r message=FALSE, warning=FALSE, eval=FALSE}

parallel.helper(fn=apply.assign.mb.fn.to.file.and.write.out, 
                path="/home/abrowne/projects/amppd_analysis/data/MatrixEQTL_output/celltype_PP_samples_filtered/", 
                pattern="wrangled.csv", 
                cores.to.use=6)

```

* check that all files contain cols, and if they don't, run relevant functions  

```{r message=FALSE, warning=FALSE}

l = list.files(path="/home/abrowne/projects/amppd_analysis/data/MatrixEQTL_output/celltype_PP_samples_filtered/", pattern="wrangled.csv", full.names = T)

for(i in l){
  len=vroom::vroom(i) %>% colnames(.)
  if( ( len %>% length(.) ) != 18 ){
    print(paste(len %>% length(), i))
    print(len)
  }
  
  # map rsid if col isn't present
  if( !("SNP" %in% len) ){
    
    annotate.wrangled.pheno.file.rsid.overwrite(i)
    
  }
  # calculate mb block if col isn't present
  if( !("mb.block.id" %in% len) ){
    
    apply.assign.mb.fn.to.file.and.write.out(i)
    
  }
  
  # remove extraneous join cols if they're present 
  if( (".x" %in% len)  | (".y" %in% len) ){
    
    vroom::vroom(i) %>%
      dplyr::select(-contains(".x"), -contains(".y")) %>%
      vroom::vroom_write(x=., file=i)
    
  }
  
}

```

# Convert rsIDs to variantIDs  

* This is because a variantID is necessary for querying of the Open Targets Genetics API  
* To do this, I will need to read in the bim files and generate a variantID column from the chr, pos, alt, ref cols  

```{r}

# .bim is the extended variant information file - contains snp, pos, chr, ref, alt
# read in this for PP and PD and bind together

bim.data.pd.pp = dplyr::bind_rows(
  genio::read_bim(file="/home/abrowne/projects/amppd_analysis/data/genomics_bed_bim_fam_from_rosalind/PP_all_chrs_maf0.05.bim", verbose = TRUE) %>% dplyr::mutate(cohort="PP")
) %>% 
  dplyr::mutate(variant.id=paste0(chr, "_", pos, "_", alt, "_", ref))

```

* Map variant IDs to results df  

```{r, eval=FALSE}

get.variantID.overwrite = function(file.path){
  
  d = vroom::vroom(file.path)
  
  if( (dim(d)[1]!=0)){
    if( ("variant.id" %in% colnames(d)) ){
      
      d %>%
        dplyr::left_join(x=., y=bim.data.pd.pp %>%
                           dplyr::mutate(snp.chr.pos=paste0("chr",chr,":",pos)) %>%
                           dplyr::select(snp.chr.pos, variant.id, cohort),
                         by=c("snp.chr.pos", "cohort")) %>%
        #dplyr::rename(matrixeqtl.model.run=matreqtl.model.run) %>% 
        vroom::vroom_write(x=., file=file.path)
    }
  }
}

```

* Implement `get.variantID.overwrite()` 

```{r message=FALSE, warning=FALSE}

parallel.helper(fn=get.variantID.overwrite, path="/home/abrowne/projects/amppd_analysis/data/MatrixEQTL_output/celltype_PP_samples_filtered/", pattern="_wrangled.csv", cores.to.use=5)

```

<!-- # Annotate data using the Open Targets Genetics API   -->

<!-- * Resources I used to make this work:   -->
<!-- + https://genetics-docs.opentargets.org/data-access/graphql-api   -->
<!-- + https://www.youtube.com/watch?v=_sZR0VxpwqE   -->
<!-- + https://api.genetics.opentargets.org/graphql/ -->

<!-- * Testing the API   -->

<!-- ```{r} -->

<!-- # Set study_id and variant_id variables -->
<!-- variant_id <- "2_858109_C_T" -->

<!-- # Build query string -->
<!-- query_string=" -->
<!-- query var($variantId: String!){ -->
<!--   variantInfo(variantId: $variantId){ -->
<!--     id -->
<!--     chromosome -->
<!--     position -->
<!--     refAllele -->
<!--     altAllele -->
<!--     nearestGene { -->
<!--       id -->
<!--       symbol -->
<!--       bioType -->
<!--     } -->
<!--   } -->
<!-- }" -->

<!-- # Set base URL of Genetics Portal GraphQL API endpoint -->
<!-- base_url <- "https://api.genetics.opentargets.org/graphql" -->

<!-- # Set variables object of arguments to be passed to endpoint -->
<!-- variables <- list("variantId" = variant_id) -->

<!-- # Construct POST request body object with query string and variables -->
<!-- post_body <- list(query = query_string, variables = variables) -->

<!-- # Perform POST request -->
<!-- r <- POST(url=base_url, body=post_body, encode='json') -->

<!-- # make res (list of lists) into df -->
<!-- r.data.slot = content(r)$data  -->

<!-- if( is.null(r.data.slot$variantInfo$nearestGene)==TRUE ){ -->
<!--   r.data.slot$variantInfo$nearestGene = NA -->
<!-- } -->

<!-- r.data.slot %>%  -->
<!--   lapply(., data.frame, stringsAsFactors = FALSE) %>%  -->
<!--   dplyr::bind_rows(.) -->

<!-- ``` -->

<!-- * Running function to query all vars on each file: `/home/abrowne/projects/amppd_analysis/scripts/query-api-genetics-opentargets-with-helper-funs.R`   -->
<!-- ```{bash} -->

<!-- cd /home/abrowne/projects/amppd_analysis/scripts -->
<!-- Rscript query-api-genetics-opentargets-with-helper-funs.R -->

<!-- ``` -->

<!-- * Check that it's worked:  -->

<!-- ```{r} -->

<!-- check.df = vroom::vroom("./data/MatrixEQTL_output/PD_Control_pheno=ENSG00000198888_maf=0.05_phenotype=expression_model=LINEAR_wrangled.csv") -->

<!-- ``` -->
































<!-- # Annotate with information from the GWAS catalogue -->

<!-- * Load the GWAS catalogue -->
<!-- * The full GWAS catalogue was downloaded from: https://www.ebi.ac.uk/gwas/docs/file-downloads -->

<!-- ```{r} -->

<!-- gwas.cat = read_delim("./reference/full", delim = "\t") %>% -->
<!--   dplyr::relocate(CHR_ID, CHR_POS, SNPS, `REPORTED GENE(S)`, MAPPED_GENE, `DISEASE/TRAIT`) -->

<!-- ``` -->

<!-- * Map GWAS catalogue to target SNPs -->

<!-- ```{r} -->

<!-- # matrixeqtl.out.rsid.df %>% -->
<!-- #   dplyr::filter(matrixeqtl.model.run == "LINEAR") %>% -->
<!-- #   dplyr::filter(phenotype.category == "expression") %>% -->
<!-- #   dplyr::filter(diagnosis == "Case") %>% -->
<!-- #   dplyr::filter(FDR<0.01) %>% -->
<!-- #   dplyr::arrange(FDR) %>% -->
<!-- #   dplyr::rename(SNPS=SNP) %>% -->
<!-- #   dplyr::left_join(x=., y=gwas.cat, by=c("SNPS")) %>% -->
<!-- #   tidyr::drop_na(`DISEASE/TRAIT`) -->

<!-- ``` -->

# Session Info

```{r}
sessionInfo()
```

